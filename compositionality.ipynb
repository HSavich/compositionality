{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import fasttext\n",
    "import io\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in vectors from fasttext:\n",
    "https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname, n_vecs):\n",
    "#get vectors for the top n_vecs most frequent words\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "        i += 1\n",
    "        if i >= n_vecs:\n",
    "            res = {key:np.array([i for i in data[key]]) for key in data}\n",
    "            return(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vecs = 100000\n",
    "vecs = load_vectors(\"wiki-news-300d-1M.vec\", num_vecs)\n",
    "keys = list(vecs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19469498133283902\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    return(v1.dot(v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "    \n",
    "    \n",
    "trials = 100\n",
    "cumsum = 0\n",
    "for i in range(trials):\n",
    "    word1 = keys[np.random.randint(num_vecs)]\n",
    "    word2 = keys[np.random.randint(num_vecs)]\n",
    "    cumsum += cosine_similarity(vecs[word1], vecs[word2])\n",
    "cumsum = cumsum / trials\n",
    "\n",
    "print(cumsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the vectors were uniformly distributed in the space, we would expect the above experiment to show an avg cosine similarity of zero. The magnitude of the avg cos similarity may be considered to quantify \"hubness\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(query_vec, k = 1):\n",
    "    closest_matches = [(-1.1, \"not a word\")]\n",
    "    cos_theta_thresh = min(closest_matches)[0]\n",
    "    for key in keys:\n",
    "        cos_theta = cosine_similarity(vecs[key], query_vec)\n",
    "        if cos_theta > cos_theta_thresh:\n",
    "            closest_matches.append((cos_theta, key))\n",
    "            closest_matches.sort(reverse = True)\n",
    "            closest_matches = closest_matches[:k]\n",
    "            cos_theta_thresh = min(closest_matches)[0]\n",
    "    return closest_matches\n",
    "\n",
    "def show_knn(query_vec, k = 1):\n",
    "    knn = get_knn(query_vec, k = k)\n",
    "    for pair in knn:\n",
    "        print(f\"{pair[1]}: {pair[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a nice-to-handle word vector data structure, and a function for retrieving nearest neighbors, we can play around with the vector space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.860e-02,  3.510e-02,  3.920e-02,  1.570e-01, -2.760e-02,\n",
       "        2.400e-03, -7.510e-02, -9.310e-02,  1.010e-01, -2.100e-03,\n",
       "        5.930e-02,  1.100e-02,  1.730e-01,  5.630e-02,  2.550e-02,\n",
       "        2.320e-02,  1.158e-01,  4.220e-02,  6.080e-02, -1.078e-01,\n",
       "       -1.808e-01,  4.340e-02, -1.358e-01,  7.340e-02, -1.350e-01,\n",
       "        2.790e-02, -1.970e-02,  1.795e-01, -1.206e-01,  4.450e-02,\n",
       "        7.580e-02, -1.076e-01,  1.460e-02,  8.420e-02, -2.139e-01,\n",
       "       -6.450e-02,  4.800e-02,  3.930e-02,  5.630e-02,  2.820e-02,\n",
       "       -6.820e-02,  2.524e-01, -4.160e-02, -9.900e-03, -7.130e-02,\n",
       "       -4.260e-02,  6.570e-02, -1.421e-01,  9.200e-03, -1.495e-01,\n",
       "        1.142e-01, -1.868e-01, -6.275e-01, -9.090e-02, -7.850e-02,\n",
       "       -1.130e-02, -1.500e-03,  1.011e-01,  3.430e-02, -8.040e-02,\n",
       "        9.480e-02, -8.250e-02, -1.163e-01, -1.611e-01, -3.260e-02,\n",
       "       -6.840e-02,  7.960e-02, -1.900e-01, -7.530e-02,  1.507e-01,\n",
       "       -1.954e-01, -2.490e-02,  7.890e-02,  8.710e-02,  2.300e-03,\n",
       "        8.600e-03, -3.960e-02, -1.220e-02, -1.280e-02,  8.270e-02,\n",
       "        1.770e-02,  1.033e-01,  2.020e-02, -2.200e-01, -2.330e-02,\n",
       "        2.281e-01,  1.409e-01, -2.303e-01,  2.745e-01, -1.925e-01,\n",
       "        6.930e-02, -1.065e-01,  5.770e-02, -9.290e-02, -2.423e-01,\n",
       "        1.033e-01, -9.450e-02,  1.362e-01,  4.950e-02, -1.910e-02,\n",
       "       -1.957e-01,  2.158e-01, -5.640e-02, -1.517e-01,  1.500e-02,\n",
       "        5.570e-02, -2.900e-03, -6.770e-02, -1.744e-01,  5.290e-02,\n",
       "        3.820e-02,  5.060e-02,  1.055e-01, -1.500e-01,  8.140e-02,\n",
       "        6.040e-02,  1.865e-01, -6.060e-02, -1.575e-01, -3.491e-01,\n",
       "       -4.750e-02,  1.667e-01,  9.810e-02, -6.660e-02,  3.410e-02,\n",
       "        2.083e-01, -1.237e-01,  3.500e-02,  5.570e-02,  2.157e-01,\n",
       "       -9.120e-02, -1.612e-01,  9.280e-02,  1.434e-01, -3.450e-02,\n",
       "        2.240e-02, -1.914e-01,  1.290e-01, -5.200e-02, -1.118e-01,\n",
       "        6.610e-02,  2.251e-01,  9.230e-02,  2.416e-01, -2.490e-02,\n",
       "        1.869e-01,  3.640e-02,  2.578e-01,  1.548e-01, -1.850e-02,\n",
       "       -1.151e-01,  1.634e-01,  4.250e-02,  9.080e-02,  6.670e-02,\n",
       "        2.720e-02,  1.011e-01,  3.670e-02, -1.140e-01, -1.073e-01,\n",
       "       -1.509e-01,  9.150e-02,  2.314e-01, -5.760e-02, -8.000e-04,\n",
       "        5.540e-02,  1.646e-01, -5.860e-02,  7.950e-02,  1.460e-02,\n",
       "       -6.020e-02, -2.519e-01,  6.400e-02, -7.200e-03,  1.340e-01,\n",
       "       -2.910e-02,  3.128e-01, -1.176e-01,  9.160e-02, -1.446e-01,\n",
       "       -4.370e-02,  3.425e-01, -3.280e-02, -1.689e-01,  7.210e-02,\n",
       "       -1.475e-01,  4.380e-02, -5.590e-02, -2.209e-01,  1.215e-01,\n",
       "        2.670e-02, -1.101e-01, -1.079e-01,  2.026e-01, -1.369e-01,\n",
       "        1.948e-01,  8.910e-02,  1.190e-01,  1.519e-01, -7.360e-02,\n",
       "       -1.440e-02, -1.140e-02, -3.830e-02, -8.000e-04,  1.026e-01,\n",
       "        1.203e-01, -3.240e-02, -2.343e-01,  1.820e-02,  1.081e-01,\n",
       "        1.920e-01, -7.300e-03,  6.590e-02,  4.000e-04, -2.740e-01,\n",
       "        5.990e-02, -1.356e-01,  5.250e-02, -1.370e-02, -1.826e-01,\n",
       "       -2.560e-02, -1.438e-01,  1.326e-01, -5.040e-02, -8.200e-02,\n",
       "       -3.185e-01,  6.480e-02, -1.620e-02, -3.550e-02, -1.137e-01,\n",
       "        3.840e-02,  8.380e-02,  4.042e-01, -1.456e-01,  9.770e-02,\n",
       "       -1.663e-01,  1.610e-02, -4.390e-02, -2.679e-01, -5.260e-02,\n",
       "        1.318e-01,  2.640e-02, -4.810e-02, -6.440e-02, -5.210e-02,\n",
       "        7.880e-02,  1.230e-02,  2.590e-02, -5.340e-02,  3.990e-01,\n",
       "       -9.030e-02,  2.510e-02,  7.490e-02, -2.280e-02, -2.410e-02,\n",
       "        1.820e-02, -1.663e-01,  2.396e-01, -2.150e-02, -6.480e-02,\n",
       "        3.240e-02,  2.380e-02,  5.380e-02, -1.492e-01, -3.742e-01,\n",
       "       -4.930e-02, -8.710e-02,  8.370e-02, -1.000e-01, -7.940e-02,\n",
       "        5.820e-02,  9.000e-02,  1.530e-02,  2.790e-02, -2.506e-01,\n",
       "        3.740e-02,  1.781e-01,  9.080e-02, -2.480e-02,  2.630e-02,\n",
       "       -3.890e-02, -3.540e-02,  2.620e-02,  2.117e-01,  3.110e-02,\n",
       "       -8.860e-02, -6.290e-02, -5.100e-02, -7.110e-02,  8.680e-02,\n",
       "        9.270e-02, -1.579e-01,  4.480e-02,  4.790e-02,  2.077e-01,\n",
       "        1.582e-01,  1.750e-02, -2.150e-02,  4.610e-02, -5.540e-02])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love: 0.9999999999999999\n",
      "hate: 0.7127140373945532\n",
      "loving: 0.7031040644656243\n",
      "loved: 0.677062808092265\n",
      "loves: 0.6755636195802975\n"
     ]
    }
   ],
   "source": [
    "show_knn(vecs[\"love\"], k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunhill: -0.049358651590376765\n",
      "compels: -0.05567376493485118\n",
      "cross-sections: -0.06605214092327753\n"
     ]
    }
   ],
   "source": [
    "empty_half_plane = np.zeros(300)\n",
    "empty_half_plane[52] = 1\n",
    "show_knn(empty_half_plane, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That the above vector has a nearest neighbor with negative cosine similarity indicates there is no word embedding with 53rd coord > 0 => there is an empty half plane"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98b39e574d87cc5692564f8530d6c80c20e25b792bac53804b03115375c4a8d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
